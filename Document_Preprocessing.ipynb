{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82ad622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "\n",
    "def text_formatter(text:str)->str:\n",
    "    clean_text = text.replace(\"\\n\" , \" \").strip()\n",
    "    return clean_text\n",
    "def open_read_pdf(pdf_path:str) -> str : \n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "    for page_num , page in tqdm(enumerate(doc)) : \n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\":page_num,\n",
    "                                \"page_char_count\":len(text),\n",
    "                                \"page_word_count\":len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\":len(text.split('. ')),\n",
    "                                \"page_token_count\":len(text)/4 ,# 1 token ~ 4 chars\n",
    "                                \"text\":text})\n",
    "        \n",
    "    return pages_and_texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8b54ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [00:00, 225.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'page_number': 50,\n",
       " 'page_char_count': 994,\n",
       " 'page_word_count': 195,\n",
       " 'page_sentence_count_raw': 3,\n",
       " 'page_token_count': 248.5,\n",
       " 'text': 'Boeing 737 Operations Manual    Normal Procedures Chapter NP Flight Patterns Section 30     Copyright © The Boeing Company. See title page for details. D6-27370-TBC NP.30.1 NP.30 Normal Procedures-Flight Patterns Takeoff   VR • Rotate  3000 feet  • One or 2 engine   Thrust set • Manually advance Positive rate of climb  • Gear up flap retraction altitude  • Select flaps up maneuvering speed  • Set/verify climb thrust (2 engine) • • • • thrust to stabilize • Press TO/GA  Acceleration height  At 400 feet AGL • Select roll mode  • VNAV engaged • • • LNAV armed (as required) (normally 1000 ft.)  (as installed)  • Retract flaps on schedule  climb speed V1 • Takeoff thrust by 60 knots  • V2+15 to 25 knots (2 engine)  • V2 to V2+20 knots (1 engine) Flaps up • Maintain flaps up maneuvering speed  • Set max continuous thrust (1 engine) • After Takeoff checklist • Non–Normal checklist (if required) • Maintain flaps up maneuvering speed (2engine)  or select LVL CHG (1 engine) August 30, 2000'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path=\"Boeing B737 Manual.pdf\"\n",
    "\n",
    "pages_and_texts = open_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483eb905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2655</td>\n",
       "      <td>883</td>\n",
       "      <td>655</td>\n",
       "      <td>663.75</td>\n",
       "      <td>Boeing 737 Operations Manual   Normal Procedur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1687</td>\n",
       "      <td>623</td>\n",
       "      <td>513</td>\n",
       "      <td>421.75</td>\n",
       "      <td>Boeing 737 Operations Manual   Copyright © The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2225</td>\n",
       "      <td>320</td>\n",
       "      <td>19</td>\n",
       "      <td>556.25</td>\n",
       "      <td>Boeing 737 Operations Manual    Normal Procedu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2269</td>\n",
       "      <td>350</td>\n",
       "      <td>15</td>\n",
       "      <td>567.25</td>\n",
       "      <td>Boeing 737 Operations Manual    Normal Procedu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1346</td>\n",
       "      <td>216</td>\n",
       "      <td>11</td>\n",
       "      <td>336.50</td>\n",
       "      <td>Boeing 737 Operations Manual    Normal Procedu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0            0             2655              883                      655   \n",
       "1            1             1687              623                      513   \n",
       "2            2             2225              320                       19   \n",
       "3            3             2269              350                       15   \n",
       "4            4             1346              216                       11   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0            663.75  Boeing 737 Operations Manual   Normal Procedur...  \n",
       "1            421.75  Boeing 737 Operations Manual   Copyright © The...  \n",
       "2            556.25  Boeing 737 Operations Manual    Normal Procedu...  \n",
       "3            567.25  Boeing 737 Operations Manual    Normal Procedu...  \n",
       "4            336.50  Boeing 737 Operations Manual    Normal Procedu...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df  = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec0da932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>72.500000</td>\n",
       "      <td>1533.705479</td>\n",
       "      <td>260.753425</td>\n",
       "      <td>36.589041</td>\n",
       "      <td>383.426370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.290661</td>\n",
       "      <td>654.736495</td>\n",
       "      <td>168.919428</td>\n",
       "      <td>125.344033</td>\n",
       "      <td>163.684124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>45.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.250000</td>\n",
       "      <td>958.500000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>239.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>72.500000</td>\n",
       "      <td>1525.500000</td>\n",
       "      <td>211.500000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>381.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>108.750000</td>\n",
       "      <td>2034.500000</td>\n",
       "      <td>302.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>508.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>145.000000</td>\n",
       "      <td>2916.000000</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count   146.000000       146.000000       146.000000               146.000000   \n",
       "mean     72.500000      1533.705479       260.753425                36.589041   \n",
       "std      42.290661       654.736495       168.919428               125.344033   \n",
       "min       0.000000       181.000000        28.000000                 3.000000   \n",
       "25%      36.250000       958.500000       161.000000                 6.000000   \n",
       "50%      72.500000      1525.500000       211.500000                11.500000   \n",
       "75%     108.750000      2034.500000       302.500000                16.000000   \n",
       "max     145.000000      2916.000000       963.000000               729.000000   \n",
       "\n",
       "       page_token_count  \n",
       "count        146.000000  \n",
       "mean         383.426370  \n",
       "std          163.684124  \n",
       "min           45.250000  \n",
       "25%          239.625000  \n",
       "50%          381.375000  \n",
       "75%          508.625000  \n",
       "max          729.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b29310f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text:str,chunk_size:int=500) -> list:\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    words = text.split()\n",
    "    for word in words : \n",
    "        if len(current_chunk) + len(word) + 1 <= chunk_size : \n",
    "            current_chunk += (word + \" \")\n",
    "        else : \n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = word + \" \"\n",
    "    ## adding the last chunk if it is not empty    \n",
    "    if current_chunk : \n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks     \n",
    "\n",
    "\n",
    "def chunks_pdf_pages(pages_and_texts:list,chunk_size:int=500)->list[dict]:\n",
    "    all_chunks = []\n",
    "    for page in pages_and_texts : \n",
    "        page_number = page[\"page_number\"]\n",
    "        page_text = page[\"text\"]\n",
    "        \n",
    "        chunks = chunk_text(page_text,chunk_size=chunk_size)\n",
    "        for i,chunk in enumerate(chunks) : \n",
    "            all_chunks.append({\n",
    "                \"page_number\":page_number,\n",
    "                \"chunk_index\" : i,\n",
    "                \"chunk_char_count\":  len(chunk),\n",
    "                \"chunk_word_count\" : len(chunk.split()),\n",
    "                \"chunk_token_count\": len(chunk)/4,\n",
    "                \"chunk_text\":chunk\n",
    "            })\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f97dd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 522\n",
      "Chunk sample (page 57) : Boeing 737 Operations Manual Supplementary Procedures - Fuel Copyright © The Boeing Company. See title page for details. SP.12.2 D6-27370-TBC Refueling Fuel Load Distribution Main tanks No. 1 and No. \n"
     ]
    }
   ],
   "source": [
    "chunked_pages = chunks_pdf_pages(pages_and_texts,chunk_size=500)\n",
    "print(f\"Total chunks: {len(chunked_pages)}\")\n",
    "print(f\"Chunk sample (page {chunked_pages[200][\"page_number\"]}) : {chunked_pages[200][\"chunk_text\"][:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec7dff",
   "metadata": {},
   "source": [
    "## Fixed-Size Chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59ad7923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random,textwrap \n",
    "# -------------------------Sampling & Pretty Printing--------------------------\n",
    "def _scattered_indices(n:int,k:int,jitter_frac:float=0.08) -> list[int] : \n",
    "    if k<=0 :\n",
    "        return []\n",
    "    if k==1 : \n",
    "        return [random.randrange(n)]\n",
    "    anchors = [int(round(i*(n-1)/(k-1))) for i in range(k)]\n",
    "    out,seen = [],set()\n",
    "    radius = max(1,int(n*jitter_frac))\n",
    "    for a in anchors : \n",
    "        lo,hi = max(0,a-radius) , min(n-1,a+radius)\n",
    "        j = random.randint(lo,hi)\n",
    "        if j not in seen : \n",
    "            out.append(j);seen.add(j)\n",
    "    while len(out)<k : \n",
    "        r = random.randrange(n)\n",
    "        if r not in seen :\n",
    "            out.append(r),seen.add(r)\n",
    "    return out\n",
    "\n",
    "def _draw_boxed_chunk(c:dict,wrap_at:int=96) -> str : \n",
    "    header = (\n",
    "        f\"Chunk p{c['page_number']} -- idx {c['chunk_index']}  |  \"\n",
    "        f\"Chars {c['chunk_char_count']} -- words {c['chunk_word_count']} -- ~tokens {c['chunk_token_count']} \"\n",
    "    )\n",
    "    \n",
    "    wrapped_lines = textwrap.wrap(\n",
    "        c['chunk_text'],width=wrap_at,break_long_words=False,replace_whitespace=False\n",
    "    )\n",
    "    context_width = max([0,*map(len,wrapped_lines)])\n",
    "    box_width = max(len(header),context_width+2)\n",
    "    \n",
    "    top    = \"=\" + (box_width+4)*\"=\" + \"=\"\n",
    "    hline  = \"||\" + header.ljust(box_width) + \"  ||\"\n",
    "    sep    = \"||-\" + \"-\"*box_width + \"-||\"\n",
    "    body   = \"\\n\".join(\"||\" + line.ljust(box_width--2)+'||' for line in wrapped_lines) or \\\n",
    "        (\"||\"+\"\".ljust(box_width-2) + \"||\")\n",
    "    bottom = \"=\" + (box_width+4)*\"=\" + \"=\"\n",
    "    \n",
    "    return \"\\n\".join([top,hline,sep,body,bottom])\n",
    "\n",
    "def show_random_chunks(pages_and_texts,chunk_size:int=500,k:int=5,seed:int | None = 42) : \n",
    "    if seed is not None : \n",
    "        random.seed(seed)\n",
    "    all_chunks = chunks_pdf_pages(pages_and_texts,chunk_size)\n",
    "    if not all_chunks : \n",
    "        print(f\"No chunks are available.\")\n",
    "        return\n",
    "    idxs = _scattered_indices(len(all_chunks),k)\n",
    "    print(f\"Showing {len(idxs)} scattered random chunks ou of {len(all_chunks)} in total:\\n \")\n",
    "    for i ,idx in enumerate(idxs,1):\n",
    "        print(f\"#{i}\")\n",
    "        print(_draw_boxed_chunk(all_chunks[idx]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a41b4624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 2 scattered random chunks ou of 522 in total:\n",
      " \n",
      "#1\n",
      "=======================================================================================================\n",
      "||Chunk p11 -- idx 1  |  Chars 493 -- words 53 -- ~tokens 123.25                                     ||\n",
      "||---------------------------------------------------------------------------------------------------||\n",
      "||....................................................................................Test FLIGHT    ||\n",
      "||RECORDER OFF light – Illuminated FLIGHT RECORDER test switch – TEST FLIGHT RECORDER OFF light –    ||\n",
      "||Extinguished FLIGHT RECORDER test switch – NORMAL MACH AIRSPEED WARNING TEST switches              ||\n",
      "||............................ Push Verify clacker sounds. STALL WARNING TEST switches               ||\n",
      "||................................................ Push Verify control column vibration when each    ||\n",
      "||switch is pushed. Note: The stall                                                                  ||\n",
      "=======================================================================================================\n",
      "\n",
      "#2\n",
      "=====================================================================================================\n",
      "||Chunk p133 -- idx 4  |  Chars 212 -- words 35 -- ~tokens 53.0                                    ||\n",
      "||-------------------------------------------------------------------------------------------------||\n",
      "||ceiling to locate the exits and provide general illumination in the area of the exits.           ||\n",
      "||Self–illuminating exit locator signs are installed at the forward, middle, and aft end of the    ||\n",
      "||passenger cabin. March 15, 2002                                                                  ||\n",
      "=====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert 'pages_and_texts' in globals() , \"Run : pages_and_texts = open_and_read_pdf(odf_path) first.\"\n",
    "show_random_chunks(pages_and_texts,chunk_size=500,k=2,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3bd65",
   "metadata": {},
   "source": [
    "## LLM-based Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "252e478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Dict\n",
    "\n",
    "HF_API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct\"\n",
    "HF_HEADERS = {\"Authorization\": \" ## Access Token ##\"}  # paste your token here\n",
    "\n",
    "def llm_based_chunking(text: str, chunk_size: int = 1000) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Using Hugging Face hosted LLM to find semantically coherent chunk boundaries\n",
    "    given a target chunk size.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_chunk_boundary(text_segment:str) -> int : \n",
    "        prompt = f\"\"\"\n",
    "            Analyze the following text and identify the best point to split it \n",
    "            into two semantically coherent parts.\n",
    "            The split should occur near {chunk_size} characters \n",
    "            Text:\n",
    "            \\\"\\\"\\\"{text_segment}\"\n",
    "            Return only the integer index (character position) within this text\n",
    "            where the split should occur.Do not return any explanation.\n",
    "            \"\"\"\n",
    "            \n",
    "        payload = {\"inputs\": prompt, \"parameters\": {\"max_new_tokens\": 20}}\n",
    "        response = requests.post(HF_API_URL, headers=HF_HEADERS, json=payload)\n",
    "        result = response.json()\n",
    "\n",
    "        if isinstance(result, list) and len(result) > 0 and \"generated_text\" in result[0]:\n",
    "            split_str = result[0][\"generated_text\"].strip()\n",
    "        else:\n",
    "            split_str = str(chunk_size)\n",
    "\n",
    "        try:\n",
    "            split_point = int(split_str)\n",
    "        except ValueError:\n",
    "            split_point = chunk_size\n",
    "\n",
    "        return split_point\n",
    "    chunks = []\n",
    "    remaining_text = text \n",
    "    while len(remaining_text) > chunk_size : \n",
    "        text_window = remaining_text[:chunk_size]\n",
    "        split_point  = get_chunk_boundary(text_window)\n",
    "        if split_point < 100 or split_point> len(text_window)-100 : \n",
    "            split_point = chunk_size\n",
    "        chunks.append(remaining_text[:split_point].strip())\n",
    "        remaining_text = remaining_text[split_point:].strip()\n",
    "    if remaining_text:\n",
    "        chunks.append(remaining_text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f5720de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_based_chunk_pdf_pages(pages_and_texts:List[Dict],chunk_size:int=1000) -> List[Dict] : \n",
    "    all_chunks = []\n",
    "    for page in tqdm(pages_and_texts,desc=\"LLM based chunking pages\") : \n",
    "        page_number = page[\"page_number\"]\n",
    "        page_text = page[\"text\"]\n",
    "        \n",
    "        chunks = llm_based_chunking(page_text,chunk_size)\n",
    "        for i,chunk in enumerate(chunks) : \n",
    "            all_chunks.append({\n",
    "                \"page_number\":page_number,\n",
    "                \"chunk_index\" : i, \n",
    "                \"chunk_char_count\":  len(chunk),\n",
    "                \"chunk_word_count\" : len(chunk.split()),\n",
    "                \"chunk_token_count\": len(chunk)/4,\n",
    "                \"chunk_text\":chunk\n",
    "            })\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chunked_pages = llm_based_chunk_pdf_pages(pages_and_texts,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2b4b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Images extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "import fitz # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_images_from_pdf(pdf_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    for page_index, page in enumerate(pdf):\n",
    "        image_list = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(image_list, start=1):\n",
    "            xref = img[0]\n",
    "            base_image = pdf.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_path = os.path.join(output_dir, f\"page{page_index+1}_img{img_index}.{image_ext}\")\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "    print(\"✅ Images extracted successfully.\")\n",
    "\n",
    "# Example:\n",
    "extract_images_from_pdf(\"Boeing B737 Manual.pdf\", \"images/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d4a58dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rendered 146 pages as images.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def render_page_as_image(pdf_path, output_dir, zoom=2.0):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pdf = fitz.open(pdf_path)\n",
    "\n",
    "    for page_number, page in enumerate(pdf, start=1):\n",
    "        # render page at higher resolution\n",
    "        matrix = fitz.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=matrix, alpha=False)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"page_{page_number}.png\")\n",
    "        pix.save(output_path)\n",
    "    print(f\"✅ Rendered {len(pdf)} pages as images.\")\n",
    "\n",
    "# Example\n",
    "render_page_as_image(\"Boeing B737 Manual.pdf\", \"page_images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0506c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DHIA\\Desktop\\My Projects\\Rag-B737-Service-Repo\\B737venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "c:\\Users\\DHIA\\Desktop\\My Projects\\Rag-B737-Service-Repo\\B737venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DHIA\\.cache\\huggingface\\hub\\models--Salesforce--blip-image-captioning-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/rendered_pages/page_110.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m processor = BlipProcessor.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mSalesforce/blip-image-captioning-base\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m model = BlipForConditionalGeneration.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mSalesforce/blip-image-captioning-base\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m image = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/rendered_pages/page_110.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m inputs = processor(image, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m caption = model.generate(**inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DHIA\\Desktop\\My Projects\\Rag-B737-Service-Repo\\B737venv\\Lib\\site-packages\\PIL\\Image.py:3493\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3492\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3493\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3494\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/rendered_pages/page_110.png'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feb7a5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a page from the book, ' do not for light '\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"rendered_pages/page_135.png\")\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "caption = model.generate(**inputs)\n",
    "print(processor.decode(caption[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "B737venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
